{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06e44435-9109-4c47-823e-58c81db9b55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hmacdope/mambaforge/envs/openadmet_toolkit2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from openadmet.toolkit.database.chembl import PermissiveChEMBLTargetCurator\n",
    "from openadmet.toolkit.chemoinformatics.rdkit_funcs import canonical_smiles, smiles_to_inchikey\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import datamol as dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b405a219-1466-48c2-a29f-dced8fd1621b",
   "metadata": {},
   "source": [
    "# Curating basic pChEMBL data and pushing to a remote intake catalog\n",
    "\n",
    "Our goal is to curate activity data from ChEMBL and push this to a remote location with a catalog that can be used by others to look up our data. This will enable consistency and rapid dissemination of our work as well as an over-time evolution of our data curation practices. \n",
    "\n",
    "We use the `Intake` package for a lightweight self-describing data parsing workflow. Read more about intake here: https://intake.readthedocs.io/en/latest/index.html\n",
    "\n",
    "\n",
    "Here we gather `pChEMBL` data permissivley from ChEMBL (ie without activity based curation) for our 5 main targets (AHR, PXR, CYP3A4, CYP2C9, CYP2D6) and also additional target CYP2J2.\n",
    "\n",
    "We then aggregate `pChEMBL` measurements on the same compound by taking the mean. This is the most basic form of curation available, but serves as a good baseline for our initial models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a9c4d-cdd2-4b60-8cbf-7d9bf46c1321",
   "metadata": {},
   "source": [
    "## gather ChEMBL data\n",
    "\n",
    "First we need to gather in our data from ChEMBL using our SQL API defined in `openadmet-toolkit`\n",
    "\n",
    "We use `OPENADMET_SMILES` and `OPENADMET_INCHIKEY` to distinguish our ML ready representation from the source SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb8d965-3a97-4f3d-9a16-0df116da5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_chembl_data_for_target(target_name: str, chembl_tid: str, chembl_ver: int):\n",
    "    print(f\"working on target {target_name}\")\n",
    "    pctc = PermissiveChEMBLTargetCurator(chembl_target_id=chembl_tid, version=chembl_ver)\n",
    "    activity_data = pctc.get_activity_data(return_as=\"df\")\n",
    "    print(\"canonicalising raw data\")\n",
    "    with dm.without_rdkit_log():\n",
    "        activity_data[\"OPENADMET_SMILES\"] = activity_data[\"canonical_smiles\"].progress_apply(lambda x: canonical_smiles(x))\n",
    "        activity_data[\"OPENADMET_INCHIKEY\"] = activity_data[\"OPENADMET_SMILES\"].progress_apply(lambda x: smiles_to_inchikey(x))\n",
    "    # important to canonicalise here so compound deduplication is done correctly\n",
    "    aggregated_activity = pctc.aggregate_activity_data_by_compound(canonicalise=True)\n",
    "    print(\"smiles duplicates\", aggregated_activity[\"OPENADMET_SMILES\"].duplicated().sum())\n",
    "    print(\"inchikey duplicates\", aggregated_activity[\"OPENADMET_INCHIKEY\"].duplicated().sum())\n",
    "    return aggregated_activity, activity_data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e919678-0200-45b2-b24d-0e8cf64daae6",
   "metadata": {},
   "source": [
    "## Define target metadata\n",
    "\n",
    "We need the CHEMBL codes for our targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdbfc707-57ff-44f4-9904-83925e481ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = {\n",
    "    \"AHR\": \"CHEMBL3201\",\n",
    "    \"PXR\": \"CHEMBL3401\",\n",
    "    \"CYP3A4\": \"CHEMBL340\",\n",
    "    \"CYP2C9\": \"CHEMBL3397\",\n",
    "    \"CYP2D6\": \"CHEMBL289\",\n",
    "    \"CYP2J2\": \"CHEMBL3491\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8181bab5-fa83-4f63-8284-fe6803d9512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chembl_ver = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b152e04a-6446-4932-96e2-c166a7cb7a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openadmet.toolkit.webservices.credentials import S3Settings\n",
    "from openadmet.toolkit.webservices.s3 import S3Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6278b5d-edc7-4eef-a0e5-0bf69b6b68b7",
   "metadata": {},
   "source": [
    "# Setup S3\n",
    "\n",
    "After curating our data we would like to push to a remote bucket to save both the raw data and the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649e84cc-2124-48c6-93da-6b10975ee385",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = S3Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44475bc7-926e-46d4-8dd4-b9748ebaad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"openadmet-data-public-dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7af66e88-a28c-4dc9-a684-8f2ea5ccb49d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'settings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bucket \u001b[38;5;241m=\u001b[39m S3Bucket\u001b[38;5;241m.\u001b[39mfrom_settings(settings, bucket)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'settings' is not defined"
     ]
    }
   ],
   "source": [
    "bucket = S3Bucket.from_settings(settings, bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a187a867-9b17-4b47-b05b-9d90eac16755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "854bc71d-e45c-455a-b3c1-836542242eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc825be4-b466-46b2-9c48-b4d20e7b3456",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = t.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9e5058a-ee9f-4f59-a4ae-b48f7167b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=f\"ChEMBL{chembl_ver}_permissive_{date}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcf3de96-fe45-47a9-966e-5f1bfb809883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "location_path = Path(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f7efc99-fdca-4b60-bbc1-9d36d9bd4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_path.mkdir(exist_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a19fe40-a96b-46ef-9aa0-d2c7c78d3f57",
   "metadata": {},
   "source": [
    "# Main loop\n",
    "\n",
    "Generate the data for each target and save to parquet, then push to S3 data lake with parquet files. \n",
    "\n",
    "We use parquet here for improved performance and reduced size on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79944140-dcd4-4a46-8000-a608626d5688",
   "metadata": {},
   "outputs": [],
   "source": [
    "uris_raw = {}\n",
    "uris_agg = {}\n",
    "for target, chembl_tid in targets.items():\n",
    "    agg, raw  = gather_chembl_data_for_target(target, chembl_tid, chembl_ver)\n",
    "    # TODO: make a function this is clunky\n",
    "    fname_agg = f\"ChEMBL_permissive_{target}_{chembl_tid}_aggregated.parquet\"\n",
    "    fname_raw = f\"ChEMBL_permissive_{target}_{chembl_tid}_raw.parquet\"\n",
    "    \n",
    "    agg.to_parquet(location_path/fname_agg)\n",
    "    raw.to_parquet(location_path/fname_raw)\n",
    "    \n",
    "    bucket_destination_agg = location + \"/\" + fname_agg\n",
    "    bucket.push_file(location_path/fname_agg, bucket_destination_agg)\n",
    "    bucket_destination_raw = location + \"/\" + fname_raw\n",
    "    bucket.push_file(location_path/fname_raw, bucket_destination_raw)\n",
    "\n",
    "    # get S3 URIs\n",
    "    uri_agg = bucket.to_uri(bucket_destination_agg)\n",
    "    uris_agg[target] = uri_agg\n",
    "\n",
    "    uri_raw = bucket.to_uri(bucket_destination_raw)\n",
    "    uris_raw[target] = uri_raw\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79a035b-5773-439c-9361-1a75c5688b8a",
   "metadata": {},
   "source": [
    "# Build the Intake Catalog\n",
    "\n",
    "We have sucessfully aggregted our data and pushed it to a remote destination. Now for others to consume our data, we are going to make an `Intake` catalog such that our data can be readily made available. \n",
    "\n",
    "The workflow here is drawn from the `creator` walkthrough from the main intake tutorials https://intake.readthedocs.io/en/latest/walkthrough2.html\n",
    "\n",
    "TODO: add descriptions to the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafea685-5fd0-496e-9c5e-f142345c8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a91f923-28aa-470b-9997-451bc7979a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "intake.Catalog?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada58731-1a33-463e-89dc-e5a1b0ba16fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = intake.entry.Catalog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e5245-587b-4eb8-b1c6-cf9a12379c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "uris_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301401d1-4a70-4de5-b765-638ae45b70b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "uris_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138dc87-1337-4347-ab4b-3178fb397120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2531034-2ad8-44b7-8548-4e04e9121fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in uris_agg.items():\n",
    "    cat[k+\"_aggregated\"] = intake.readers.PandasParquet(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876233c8-0bea-4753-a470-8385a79e4a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in uris_raw.items():\n",
    "    cat[k+\"_raw\"] = intake.readers.PandasParquet(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910b145a-df7a-4f36-847c-1195231f1774",
   "metadata": {},
   "source": [
    "## Push the Catalog\n",
    "\n",
    "Ok now we have made the catalog, lets push it to the remote location so it can live alongside the data. \n",
    "\n",
    "The catalog can then be used from S3 or from github etc, anything that exposes a file-like API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3474c4-2eb3-464b-8aa8-1716704f0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acecaab0-3ce9-477b-b8aa-c98ef537eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "catname = f\"CATALOG_{location}.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e4f162-a149-46d1-ac96-870dd1c04694",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.to_yaml_file(catname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eef8e3-157d-4072-bce0-c50a60afa64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_location = location+ \"/\" +catname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2730c70-f114-41ef-976e-44d57a756c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70315043-8934-4820-8b5c-8b8d8aea47c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket.push_file(catname, cat_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb0e83e-e4de-4f9c-a342-3534f18de315",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_uri = bucket.to_uri(cat_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b57897-af91-4fc7-8fc4-466c54457bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now can read the catalog from URI\n",
    "# cat = intake.Catalog.from_yaml_file(\"s3://openadmet-data-public-dev/ChEMBL34_permissive_2025-02-12/CATALOG_ChEMBL34_permissive_2025-02-12.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f27ce2a-109c-443d-b71a-e778a1c79b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
